# -*- coding: utf-8 -*-
"""COVID19-Multiclass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yfFurvJwpJDGZ-vRcgdsiQXt-CahdbLS
"""

#google drive mount if you want to access files stored in drive
from google.colab import drive
drive.mount('/content/drive')

#imports
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import cv2
import os
import glob
import shutil
from imutils import paths
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

"""#Load Images"""

#load images
dataset_dir = '/content/drive/My Drive/covid project work/dataset_for_classification' #put the path to where you stored the images
imagePaths = list(paths.list_images(dataset_dir))
data = []
labels = []

for imagePath in imagePaths:
  # extract the class label from the filename
  label = imagePath.split(os.path.sep)[-2]
  if label in ['VIRAL', 'COVID','NORMAL', 'BACTERIA']:
    image = cv2.imread(imagePath)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image, (299, 299)) #for xception model inception
    #image = cv2.resize(image, (224, 224)) #for vgg models
    #image = cv2.resize(image, (331, 331)) #for NASnetLarge models


    # update the data and labels lists
    data.append(image)
    labels.append(label)
  else: continue

print(len(data))
print(len(labels))

# convert the data and labels to NumPy arrays while scaling the pixel
# intensities to the range [0, 255]
data = np.array(data) / 255.0
labels = np.array(labels)

labels.shape

# perform one-hot encoding on the labels
labelencoder = LabelEncoder()
labels = labelencoder.fit_transform(labels)

labels = to_categorical(labels)

# split data into training and testing splits using 80% of
# the data for training and the remaining 20% for testing
(train_x, test_x, train_y, test_y) = train_test_split(data, labels,
	test_size=0.20, stratify=labels, random_state=42)

print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)

"""#the model

#Advanced Model
"""

# keras imports

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, AveragePooling2D
from tensorflow.keras.optimizers import SGD, Adam
from sklearn.metrics import classification_report
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.nasnet import NASNetLarge
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import array_to_img, img_to_array
from tensorflow.keras.optimizers import SGD
import tensorflow as tf

"""##initialize params"""

#initialize params
LR = 1e-4
EPOCHS = 50
BS = 8

#base_model = MobileNetV2(weights="imagenet", include_top=False,
#	input_shape=(224, 224, 3))
#base_model = VGG16(weights="imagenet", include_top=False,#
#	input_shape=(224, 224, 3))
#base_model = InceptionResNetV2(weights="imagenet", include_top=False,
#	input_shape=(299, 299, 3))
base_model = Xception(weights="imagenet", include_top=False,
	input_shape=(299, 299, 3))
#base_model = NASNetLarge(weights="imagenet", include_top=False,
#	input_shape=(331, 331, 3))

# first: train only the top layers (which were randomly initialized)
# freeze all convolutional layers of the choosen model
for layer in base_model.layers:
        layer.trainable = False

#define the top layer of the model
x = base_model.output
x = GlobalAveragePooling2D()(x)
#x = Flatten(name="flatten")(x)
# let's add a fully-connected layer
x = Dense(64, activation='relu')(x)
# and a logistic layer 
predictions = Dense(4, activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)
#model.summary()

adam = Adam(lr=LR, decay=1e-6, amsgrad=True)
model.compile(loss='categorical_crossentropy', optimizer=adam, metrics = ['accuracy'])

#if data augmentation is needed
datagen = ImageDataGenerator(zoom_range = 0.2, rotation_range = 10)

#history = model.fit(train_x, train_y, batch_size = BS,validation_data=(test_x, test_y), epochs = EPOCHS)
history = model.fit_generator(datagen.flow(train_x, train_y, batch_size = BS), steps_per_epoch = train_x.shape[0]/BS, epochs = EPOCHS, validation_data = (test_x, test_y))

#make prediction on test and print classification report

predIdxs = model.predict(test_x, batch_size=BS)
predIdxs = np.argmax(predIdxs, axis=1)
print(classification_report(test_y.argmax(axis=1), predIdxs,
	target_names=labelencoder.classes_))

# plot the training loss and accuracy
N = EPOCHS
#plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, N), history.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), history.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), history.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, N), history.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy for InceptionResNetV2 Model ,Amsgrad, 50 Epochs with DA")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
plt.savefig('/content/InceptionResNetV2_Amsgrad_50epochs_DA.jpg')

#save the model
model.save('/content/drive/My Drive/covid project work/Xception_Adam_50epochs.h5', save_format="h5")