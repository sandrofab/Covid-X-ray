# -*- coding: utf-8 -*-
"""Covid-Binary.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oHWCTJonqF1bvbIQGYZHA-LFVlglkYRz
"""

#google drive mount if you want to access files stored in drive
from google.colab import drive
drive.mount('/content/drive')

#imports
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import cv2
import os
import glob
import shutil
from imutils import paths
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder



# import data from metadata file
metadata_dir = '/content/drive/My Drive/covid project work/metadata_clean.csv'
metadata = pd.read_csv(metadata_dir)
# what info do we have?
print(metadata.columns)

#load images
dataset_dir = '/content/drive/My Drive/covid project work/dataset_for_classification' #put the path to where you stored the images
imagePaths = list(paths.list_images(dataset_dir))
data = []
labels = []
# loop over the image paths
for imagePath in imagePaths:
  # extract the class label from the filename
  label = imagePath.split(os.path.sep)[-2]
  if label in ['VIRAL', 'COVID','NORMAL', 'BACTERIA']:
    image = cv2.imread(imagePath)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image, (299, 299)) #for xception model inception
    #image = cv2.resize(image, (224, 224)) #for vgg models
    #image = cv2.resize(image, (331, 331)) #for NASnetLarge models
    data.append(image)
    labels.append(label)
  else: continue

len(labels)

#rename findings to have a binary classification
for i in range(len(labels)):
  if labels[i] in ['VIRAL', 'NORMAL', 'BACTERIA']:
    labels[i] = 'OTHER'

# convert the data and labels to NumPy arrays while scaling the pixel
# intensities to the range [0, 255]
data = np.array(data) / 255.0
labels = np.array(labels)

# perform one-hot encoding on the labels for multiclass
'''
labelencoder = LabelEncoder()
labels = labelencoder.fit_transform(labels)
labels = to_categorical(labels)
'''
# perform one-hot encoding on the labels for binary
labelbin = LabelBinarizer()
labels_cat = labelbin.fit_transform(labels)
labels_cat = to_categorical(labels_cat)

# partition the data into training and testing splits using 80% of
# the data for training and the remaining 20% for testing
(train_x, test_x, train_y, test_y) = train_test_split(data, labels_cat,
	test_size=0.20, stratify=labels_cat, random_state=42)

"""#The Model"""

# keras imports

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, AveragePooling2D
from tensorflow.keras.optimizers import SGD, Adam
from sklearn.metrics import classification_report
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.nasnet import NASNetLarge
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import array_to_img, img_to_array
from tensorflow.keras.optimizers import SGD
from sklearn.utils import class_weight

import tensorflow as tf

#initialize params
LR = 1e-4
EPOCHS = 20
BS = 8

#base_model = MobileNetV2(weights="imagenet", include_top=False,
#	input_shape=(224, 224, 3))
#base_model = VGG16(weights="imagenet", include_top=False,#
#	input_shape=(224, 224, 3))
base_model = InceptionResNetV2(weights="imagenet", include_top=False,
	input_shape=(299, 299, 3))
#base_model = Xception(weights="imagenet", include_top=False,
#	input_shape=(299, 299, 3))
#base_model = NASNetLarge(weights="imagenet", include_top=False,
#	input_shape=(331, 331, 3))

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional  layers of the choosen model
for layer in base_model.layers:
        layer.trainable = False

#define the head layer of the model
x = base_model.output
x = GlobalAveragePooling2D()(x)
# FC layer
x = Dense(64, activation='relu')(x)
#x = Dropout(0.5)(x)
# logistic layer 
predictions = Dense(2, activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)
#model.summary()

adam = Adam(lr=LR, decay=1e-6, amsgrad=True)
model.compile(loss='binary_crossentropy', optimizer=adam, metrics = ['binary_accuracy'])

#if data augmentation is needed
datagen = ImageDataGenerator(zoom_range = 0.2, rotation_range = 10)

#history = model.fit(train_x, train_y, batch_size = BS,validation_data=(test_x, test_y), epochs = EPOCHS)
history = model.fit(datagen.flow(train_x, train_y, batch_size = BS), steps_per_epoch = train_x.shape[0]//BS, epochs = EPOCHS, validation_data = (test_x, test_y))
#weighted_history = model.fit(datagen.flow(train_x, train_y, batch_size = BS), steps_per_epoch = train_x.shape[0]//BS, epochs = EPOCHS, validation_data = (test_x, test_y), class_weight=class_weight)

type(weighted_history)

#save model
model.save('/content/drive/My Drive/covid project work/covid_model', save_format="h5")

#make prediction on test and print classification report
pred = model.predict(test_x, batch_size=BS)
pred = np.argmax(pred, axis=1)
print(classification_report(test_y.argmax(axis=1), pred,
	target_names=labelbin.classes_))

# plot the training loss and accuracy
N = EPOCHS
#plt.style.use("ggplot")
plt.figure()
#plt.plot(np.arange(0, N), history.history["loss"], label="Train loss")
#plt.plot(np.arange(0, N), history.history["val_loss"], label="Val loss")
plt.plot(np.arange(0, N), history.history["binary_accuracy"], label="Train acc")
plt.plot(np.arange(0, N), history.history["val_binary_accuracy"], label="Val acc")
plt.title("Accuracy for Binary InceptionResNetV2  ,Amsgrad, 20 Epochs with DA")
plt.xlabel("Epoch #")
plt.ylabel("Accuracy")
plt.legend(loc="lower left")
plt.savefig('/content/Bin_InceptionResNetV2_Amsgrad_20epochs_DA_acc.jpg')

for layer in model.layers[:249]:
   layer.trainable = False
for layer in model.layers[249:]:
   layer.trainable = True

from tensorflow.keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics = ['binary_accuracy'])
history_ft = model.fit_generator(datagen.flow(train_x, train_y, batch_size = BS), steps_per_epoch = train_x.shape[0]/BS, epochs = EPOCHS, validation_data = (test_x, test_y))

predIdxs = model.predict(test_x, batch_size=BS)
predIdxs = np.argmax(predIdxs, axis=1)
print(classification_report(test_y.argmax(axis=1), predIdxs,
	target_names=labelbin.classes_))

# plot the training loss and accuracy
N = EPOCHS
#plt.style.use("ggplot")
plt.figure()
#plt.plot(np.arange(0, N), history_ft.history["loss"], label="train_loss FT")
#plt.plot(np.arange(0, N), history_ft.history["val_loss"], label="val_loss FT")
plt.plot(np.arange(0, N), history_ft.history["loss"], label="Train Loss FT")
plt.plot(np.arange(0, N), history_ft.history["val_loss"], label="Val Loss FT")
plt.title("Loss for InceptionResNetV2  ,Amsgrad, 20 Epo with DA and FT")
plt.xlabel("Epoch #")
plt.ylabel("Loss")
plt.legend(loc="lower left")
plt.savefig('/content/InceptionResNetV2_20epochs_DA_FT_LOSS_plot.jpg')

import json

a_file = open("Bin_InceptionResNetV2_Amsgrad_20epo_DA.json", "w")
json.dump(history.history, a_file)
a_file.close()

a_file = open("Bin_InceptionResNetV2_Amsgrad_20epo_DA_FT.json", "w")
json.dump(history_ft.history, a_file)
a_file.close()